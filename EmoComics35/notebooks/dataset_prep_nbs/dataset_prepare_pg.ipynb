{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC35_DIR = Path.cwd().parent / \"multimodal_er\" / \"EmoComics35\"\n",
    "DATA_FILES_DIR = EC35_DIR / \"data_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = DATA_FILES_DIR / \"emocomics35.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source text in English', 'Number of words', 'Signs with spaces',\n",
       "       'Signs without spaces', 'Translated text in Spanish; Castilian',\n",
       "       'Number of words.1', 'Signs with spaces.1', 'Signs without spaces.1',\n",
       "       'Page', 'Panel', 'Balloon', 'Annotations', 'source_file', 'file_nr',\n",
       "       'speaker', 'raw_emotions', 'emotions', 'split', 'comicbook_title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Source text in English', 'Page', 'Panel', 'Balloon', 'source_file', 'file_nr', 'speaker', 'emotions', 'split', 'comicbook_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Utterance', 'Page', 'Panel', 'Balloon', 'Source_file', 'File_nr', 'Speaker', 'Emotions', 'Split', 'Comicbook_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df = df.groupby([\"Source_file\", \"Page\"]).agg({\n",
    "    \n",
    "    \"Utterance\": list,\n",
    "    \"Speaker\": list,\n",
    "    \"Emotions\": list,\n",
    "    \"Panel\": list,\n",
    "    \"Balloon\": list,\n",
    "    \"File_nr\": list,\n",
    "    \"Split\": list,\n",
    "    \"Comicbook_title\": list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(row, col):\n",
    "    \n",
    "    return row[col][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df[\"File_nr\"] = page_df.apply(lambda row: clean_columns(row, \"File_nr\"), axis=1)\n",
    "page_df[\"Split\"] = page_df.apply(lambda row: clean_columns(row, \"Split\"), axis=1)\n",
    "page_df[\"Comicbook_title\"] = page_df.apply(lambda row: clean_columns(row, \"Comicbook_title\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df.columns = [\"SourceFile\", \"Page\", \"PageUtterances\", \"PageSpeakers\", \"PageEmotions\", \"PagePanels\", \"PageBalloons\", \"FileNr\", \"Split\", \"ComicBookTitle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_egalite(row):\n",
    "    \n",
    "    return 1 if (len(row.PageUtterances) == len(row.PageSpeakers) == len(row.PageEmotions) == len(row.PagePanels) == len(row.PageBalloons)) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df[\"egalite_check\"] = page_df.apply(lambda row: check_egalite(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egalite_check\n",
       "1    874\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_df[\"egalite_check\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df= page_df.drop(page_df.columns[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_df.to_csv(DATA_FILES_DIR / \"emocomics35_pg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_df = pd.read_csv(DATA_FILES_DIR / \"emocomics35_pg.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC35_IMAGES_DIR = EC35_DIR / \"raw_files\" / \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_path(row):\n",
    "    \n",
    "    page_nr = row.Page\n",
    "    comics_dir = \"00\" + str(row.FileNr)\n",
    "    \n",
    "    images_dir = Path(EC35_IMAGES_DIR) / comics_dir / \"images\"    \n",
    "    file_name = \"page\" + f\"{page_nr:05d}\" + \".jpg\"\n",
    "        \n",
    "    file_path = images_dir / file_name    \n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_df['image_path'] = pg_df.apply(lambda row: get_image_file_path(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_df.to_csv(DATA_FILES_DIR / \"emocomics35_pg_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_df = pd.read_csv(\"/Utilisateurs/umushtaq/multimodal_er/EmoComics35/data_files/emocomics35_pg_images.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(example):\n",
    "    example[\"image\"] = Image.open(example[\"image_path\"])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.Dataset.from_pandas(pg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f76036d9cb47bd8f8e41bc7dab6c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = hf_dataset.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c74a2275a248c6a40f7ee891569fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset.save_to_disk(\"/Utilisateurs/umushtaq/multimodal_er/EmoComics35/datasets/emocomics35_pg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mm_er)",
   "language": "python",
   "name": "multimodaler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
